{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TitanicPrediction.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"}},"cells":[{"metadata":{"id":"RUO1srr9zt1F","colab_type":"text"},"cell_type":"markdown","source":["#Classification problem: survival on Titanic\n","\n"]},{"metadata":{"id":"rfpzcVswJD7v","colab_type":"text"},"cell_type":"markdown","source":["Sigmoid function is applied to the output $(x_1,\\ldots,x_n)$ of the neural network to map: $\\mathbb{R^n} \\rightarrow (0,1)$"]},{"metadata":{"id":"PmeRre0cC4nq","colab_type":"text"},"cell_type":"markdown","source":["##Cross-entropy loss for binary classification (where labels are either $0$ or $1$):\n","$loss = -y \\cdot \\log \\hat{y}-(1-y)\\cdot\\log(1-\\hat{y})$\n","\n","where $y$ = the label, $\\hat{y}$ = the prediction"]},{"metadata":{"id":"14YdVboQjqVn","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install -U -q PyDrive\n","\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wb200ShikGuH","colab_type":"code","outputId":"e452ab5c-def6-46d8-84b9-0010a4115af1","executionInfo":{"status":"ok","timestamp":1543268905027,"user_tz":300,"elapsed":946,"user":{"displayName":"Maxim Vaysburd","photoUrl":"","userId":"05831445240371838118"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"cell_type":"code","source":["# Enter the ID of the Google Drive folder containing train.csv and test.csv files.\n","# The ID of the folder is the long string of numbers and letters in the URL of the folder in Google Drive.\n","\n","file_list = drive.ListFile({'q': \"'1nim_rYfPJPC1kR0B2AWn2-3hFKbgBlfq' in parents and trashed=false\"}).GetList()\n","for file1 in file_list:\n","  print('title: %s, id: %s' % (file1['title'], file1['id']))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["title: TitanicPrediction.ipynb, id: 12FS_uTJfTzB5BDzxAQhI9IFQpUQD8TCl\n","title: train.csv, id: 1B0IAhU3nLrSBvUTNRjRPDHYJHvv_PeRx\n","title: test.csv, id: 1pVLoe3p6rra06KLbNqfKQUp0Z0ZeqPQZ\n"],"name":"stdout"}]},{"metadata":{"id":"zwtO0wchkbNE","colab_type":"code","colab":{}},"cell_type":"code","source":["# Enter the ID of train.csv and test.csv. The IDs are printed in the output of the cell above.\n","train_downloaded = drive.CreateFile({'id': '1B0IAhU3nLrSBvUTNRjRPDHYJHvv_PeRx'})\n","train_downloaded.GetContentFile('train.csv')\n","test_downloaded = drive.CreateFile({'id': '1pVLoe3p6rra06KLbNqfKQUp0Z0ZeqPQZ'})\n","test_downloaded.GetContentFile('test.csv')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UdiGhBHzkjx3","colab_type":"code","colab":{}},"cell_type":"code","source":["# See the top rows of the train.csv file\n","!ls\n","!head train.csv\n","!head test.csv"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xlwPluWYlKNM","colab_type":"code","colab":{}},"cell_type":"code","source":["# Import pandas, which is the library for the data structures being used\n","import pandas as pd\n","\n","# Load train.csv into pandas dataframe and print the summary\n","df = pd.read_csv('train.csv')\n","df1 = pd.read_csv('test.csv')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CV1V_SoMlNCO","colab_type":"code","outputId":"26b1003b-c8d6-4914-e5bb-4f82fd91f9e1","executionInfo":{"status":"ok","timestamp":1543268910605,"user_tz":300,"elapsed":299,"user":{"displayName":"Maxim Vaysburd","photoUrl":"","userId":"05831445240371838118"}},"colab":{"base_uri":"https://localhost:8080/","height":106}},"cell_type":"code","source":["# Show shapes of the data\n","print (\"Train data shape:\", df.shape)\n","print (\"Test data shape:\", df1.shape)\n","print list(df)\n","print list(df1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["('Train data shape:', (891, 12))\n","('Test data shape:', (418, 11))\n","['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n","['PassengerId', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"],"name":"stdout"}]},{"metadata":{"id":"-wsmz4OZqpOc","colab_type":"code","outputId":"7490b8f5-731c-4982-89e5-16a29b6f5a39","executionInfo":{"status":"ok","timestamp":1543268974072,"user_tz":300,"elapsed":458,"user":{"displayName":"Maxim Vaysburd","photoUrl":"","userId":"05831445240371838118"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"cell_type":"code","source":["df = df.drop(axis=1, columns=['Ticket', 'Cabin', 'Name', 'Embarked'])\n","df1 = df1.drop(axis=1, columns=['Ticket', 'Cabin', 'Name', 'Embarked'])\n","\n","print list(df)\n","print list(df1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['PassengerId', 'Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n","['PassengerId', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']\n"],"name":"stdout"}]},{"metadata":{"id":"QgXItfBrmFvH","colab_type":"code","colab":{}},"cell_type":"code","source":["# Import math\n","import math\n","\n","# How many rows we are using for training (the rest are for evaluation)\n","num_training = 800\n","\n","df['Age'] = df['Age'].apply(lambda i: 30.0 if math.isnan(i) else i )\n","df1['Age'] = df1['Age'].apply(lambda i: 30.0 if math.isnan(i) else i )\n","df['Pclass'] = df['Pclass'].apply(lambda i: 2 if math.isnan(i) else i )\n","df1['Pclass'] = df1['Pclass'].apply(lambda i: 2 if math.isnan(i) else i )\n","df['Fare'] = df['Fare'].apply(lambda i: 10.0 if math.isnan(i) else i )\n","df1['Fare'] = df1['Fare'].apply(lambda i: 10.0 if math.isnan(i) else i )\n","df['Sex'] = df['Sex'].apply(lambda i: 1 if (not (i == \"female\")) else 0)\n","df1['Sex'] = df1['Sex'].apply(lambda i: 1 if (not (i == \"female\")) else 0)\n","df['SibSp'] = df['SibSp'].apply(lambda i: 0.0 if math.isnan(i) else i )\n","df1['SibSp'] = df1['SibSp'].apply(lambda i: 0.0 if math.isnan(i) else i )\n","df['Parch'] = df['Parch'].apply(lambda i: 0.0 if math.isnan(i) else i )\n","df1['Parch'] = df1['Parch'].apply(lambda i: 0.0 if math.isnan(i) else i )\n","\n","# Get the labels as dataframes\n","labels_df = df.iloc[:num_training,1]\n","eval_labels_df = df.iloc[num_training:,1]\n","\n","\n","# Get the features as dataframes\n","features_df = df.iloc[:num_training,2:]\n","eval_features_df = df.iloc[num_training:,2:]\n","features_df1 = df1.iloc[:,1:]\n","\n","# Get the labels as lists\n","labels = labels_df.values\n","eval_labels = eval_labels_df.values\n","\n","print labels\n","print eval_labels\n","\n","print features_df\n","print features_df1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WPkqmJekMbqB","colab_type":"code","outputId":"55d69b67-7f63-43d9-d355-5f76e1ffd569","executionInfo":{"status":"error","timestamp":1543124719780,"user_tz":300,"elapsed":1606,"user":{"displayName":"Machine Learning","photoUrl":"https://lh3.googleusercontent.com/-gIsCjJUA4Z8/AAAAAAAAAAI/AAAAAAAAABA/1GGcL4hJPiY/s64/photo.jpg","userId":"13542246114347483023"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"cell_type":"code","source":["# Import tensorflow\n","import tensorflow as tf\n","\n","# Get and print the feature names\n","headers = list(df)\n","headers1 = list(df1)\n","feature_names = headers[2:]\n","feature_names1 = headers1[1:]\n","\n","print len(labels), labels\n","print len(feature_names), feature_names"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-3-dd8b771b770d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Get and print the feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mheaders1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]}]},{"metadata":{"id":"P6MYOVYBog0x","colab_type":"code","colab":{}},"cell_type":"code","source":["!rm -r model_dir"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8AR_QQz4Mvry","colab_type":"code","colab":{}},"cell_type":"code","source":["!mkdir model_dir\n","\n","# Create a DNNClassifier with real-valued feature columns\n","# (the number of columns = number of pixels in an image)\n","\n","features = [tf.contrib.layers.real_valued_column(f) for f in feature_names]\n","# The hidden layers have 64, 32, and 16 neurons\n","# The number of classes is 10 (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n","classifier = tf.estimator.DNNClassifier(feature_columns=features,\n","                                        hidden_units=[16],\n","                                        n_classes=2,\n","                                        model_dir='model_dir')\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CZ8p7lvxObmr","colab_type":"code","colab":{}},"cell_type":"code","source":["# How many examples are being processed at a time\n","batch_size = 100\n","\n","# Train 1000 times\n","for i in range(200):\n","  # Construct the training dataset\n","  def train_input_fn():\n","    return tf.data.Dataset.from_tensor_slices((dict(features_df), labels)).shuffle(batch_size*7).repeat().batch(batch_size)\n","\n","  # Construct the evaluation dataset\n","  def eval_input_fn():\n","    return tf.data.Dataset.from_tensor_slices((dict(eval_features_df), eval_labels)).shuffle(batch_size*7).repeat().batch(batch_size)\n","\n","  # Train for 100 steps each time\n","  classifier.train(input_fn=train_input_fn, steps=200)\n","  evaluation = classifier.evaluate(input_fn=eval_input_fn, steps=1)\n","  num_training_steps = evaluation.get('global_step', '?')\n","  loss = evaluation.get('loss', '?')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AjAB1m2vaYjx","colab_type":"code","colab":{}},"cell_type":"code","source":["# Define the evaluation input function for predictions\n","def eval_input_fn1():\n","  eval_dataset1 = tf.data.Dataset.from_tensor_slices((dict(features_df1)))\n","  #eval_dataset1 = eval_dataset1.shuffle(batch_size).repeat().batch(batch_size)\n","  eval_dataset1 = eval_dataset1.batch(len(features_df1))\n","  return eval_dataset1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ltNUHIqiabVN","colab_type":"code","colab":{}},"cell_type":"code","source":["predictions = classifier.predict(\n","    input_fn=eval_input_fn1)\n","\n","submission = [\"PassengerId,Survived\"]\n","\n","counter = 0\n","for pred_dict in predictions:\n","  class_id = pred_dict['class_ids'][0]\n","  probability = pred_dict['probabilities'][class_id]\n","  pid = str(df1.iloc[counter,0])\n","  toappend =  pid + \",\" + str(class_id)\n","  submission.append(toappend)\n","  counter = counter + 1\n","  \n","print submission"],"execution_count":0,"outputs":[]}]}